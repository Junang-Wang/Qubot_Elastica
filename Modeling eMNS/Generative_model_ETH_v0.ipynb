{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ETH data to CNN generative network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "if torch.cuda.device_count():\n",
    "    device = 'cuda'\n",
    "    print('Good to go')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReadData import ReadETHFolder, ReadETHFile\n",
    "foldername=\"./ETH_Data/v/\"\n",
    "currentname = \"./ETH_Data/\"+\"currents_3787.h5\"\n",
    "file_num = 1000\n",
    "data_shape = (16,16,16,3)\n",
    "Bfield = torch.tensor(ReadETHFolder(foldername,file_num, data_shape)).permute(0,4,1,2,3)\n",
    "current = torch.tensor(ReadETHFile(currentname))\n",
    "current = current[0:Bfield.shape[0],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 16, 16, 16])\n",
      "torch.Size([1000, 8])\n"
     ]
    }
   ],
   "source": [
    "print(Bfield.shape)\n",
    "print(current.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4591],\n",
      "        [0.4241],\n",
      "        [0.3447]], dtype=torch.float64)\n",
      "tensor([[-0.4902],\n",
      "        [-0.4390],\n",
      "        [-0.3529]], dtype=torch.float64)\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([1000, 3, 16, 16, 16])\n",
      "torch.Size([1000, 3, 16, 16, 16])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#data normalization\n",
    "#find min and max value of input position and Bfield\n",
    "max_current, max_current_index = torch.max(current, dim=0, keepdim=True)\n",
    "# print(max_current)\n",
    "min_current, min_current_index = torch.min(current, dim=0, keepdim=True)\n",
    "# print(min_current)\n",
    "\n",
    "max_Bfield, max_Bfield_index = torch.max(Bfield.transpose(0,1).reshape(3,-1), dim=1, keepdim=True)\n",
    "print(max_Bfield)\n",
    "min_Bfield, min_Bfield_index = torch.min(Bfield.transpose(0,1).reshape(3,-1), dim=1, keepdim=True)\n",
    "print(min_Bfield)\n",
    "\n",
    "dimB = Bfield.shape\n",
    "dimc = current.shape\n",
    "\n",
    "minB=min_Bfield.expand(3,int(Bfield.numel()/3)).reshape(3,dimB[0],dimB[2],dimB[3],dimB[4]).transpose(0,1)\n",
    "maxB=max_Bfield.expand(3,int(Bfield.numel()/3)).reshape(3,dimB[0],dimB[2],dimB[3],dimB[4]).transpose(0,1)\n",
    "\n",
    "ave_current=0.5*(max_current.expand(dimc[0],dimc[1])+min_current.expand(dimc[0],dimc[1]))\n",
    "diff_current=0.5*(max_current.expand(dimc[0],dimc[1])-min_current.expand(dimc[0],dimc[1]))\n",
    "\n",
    "current_norm = (current-ave_current)/diff_current\n",
    "Bfield_norm = (Bfield-(minB+maxB)*0.5)/(0.5*(maxB-minB))\n",
    "\n",
    "print(min_current.shape)\n",
    "print(max_current.shape)\n",
    "print(min_Bfield.shape)\n",
    "print(max_Bfield.shape)\n",
    "\n",
    "print(minB.shape)\n",
    "print(maxB.shape)\n",
    "current_norm_max, index = torch.max(Bfield_norm.transpose(0,1).reshape(3,-1), dim=1, keepdim=True)\n",
    "print(current_norm_max)\n",
    "# torch.save(min_current, \"./normalize_data/cnn_min_current_ETH.pt\")\n",
    "# torch.save(max_current, \"./normalize_data/cnn_max_current_ETH.pt\")\n",
    "# torch.save(min_Bfield, \"./normalize_data/cnn_min_Bfield_ETH.pt\")\n",
    "# torch.save(max_Bfield, \"./normalize_data/cnn_max_Bfield_ETH.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "MaxB=maxB.cuda(0)\n",
    "MinB=minB.cuda(0)\n",
    "print(MaxB.device)\n",
    "print(MinB.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_network import Generative_net,Generative_net_test ,ResidualEMNSBlock_3d, BigBlock, weight_init, eMNS_Dataset\n",
    "###############################################\n",
    "# Config the neural network\n",
    "###############################################\n",
    "num_input = 8\n",
    "output_shape = (3,16,16,16)\n",
    "SB_args = (64,64,1,4) # (Cin, Cout, num_repeat, num_block)\n",
    "BB_args = (2,3) # (scale_factor, num_block)\n",
    "SB_block = ResidualEMNSBlock_3d \n",
    "BB_block = BigBlock\n",
    "DF = False # whether using divergence free model\n",
    "\n",
    "Generative_network = Generative_net_test(SB_args, BB_args, SB_block, BB_block, num_input=num_input, output_shape= output_shape)\n",
    "print(Generative_network)\n",
    "\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "from Training_loop import grad_loss_Jacobain\n",
    "x = torch.randn(2,8)\n",
    "y = Bfield[0:2]\n",
    "preds = Generative_network(x)\n",
    "print(preds.shape)\n",
    "loss =   F.l1_loss(preds,y)+grad_loss_Jacobain(preds,y)\n",
    "        # optimizer.zero_grad() #zero out all of gradient\n",
    "loss.backward()\n",
    "\n",
    "make_dot(loss, params=dict(Generative_network.named_parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_percent 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "Epoch 0, Iteration 57, loss = 5.7992\n",
      "Got rmse 458.5098392467805\n",
      "Got rmse 481.3073539846291\n",
      "\n",
      "Epoch 1, Iteration 114, loss = 4.0082\n",
      "Got rmse 431.3528625803291\n",
      "Got rmse 454.015699735076\n",
      "\n",
      "Epoch 2, Iteration 171, loss = 4.1551\n",
      "Got rmse 375.89507976048816\n",
      "Got rmse 396.86046837426073\n",
      "\n",
      "Epoch 3, Iteration 228, loss = 3.0449\n",
      "Got rmse 330.883540716085\n",
      "Got rmse 350.97734508456546\n",
      "\n",
      "Epoch 4, Iteration 285, loss = 2.2377\n",
      "Got rmse 283.24518737785337\n",
      "Got rmse 301.7632904292299\n",
      "\n",
      "Epoch 5, Iteration 342, loss = 2.6302\n",
      "Got rmse 222.39718394328872\n",
      "Got rmse 236.67864555037136\n",
      "\n",
      "Epoch 6, Iteration 399, loss = 2.4573\n",
      "Got rmse 194.46006090255653\n",
      "Got rmse 206.87250334728827\n",
      "\n",
      "Epoch 7, Iteration 456, loss = 1.1426\n",
      "Got rmse 174.4821140792372\n",
      "Got rmse 185.11709975258182\n",
      "\n",
      "Epoch 8, Iteration 513, loss = 1.1726\n",
      "Got rmse 149.11785034060478\n",
      "Got rmse 157.49497586515682\n",
      "\n",
      "Epoch 9, Iteration 570, loss = 0.8864\n",
      "Got rmse 132.7895344529603\n",
      "Got rmse 139.96166721167089\n",
      "\n",
      "Epoch 10, Iteration 627, loss = 1.3985\n",
      "Got rmse 119.68578718195991\n",
      "Got rmse 126.06412319285464\n",
      "\n",
      "Epoch 11, Iteration 684, loss = 0.7476\n",
      "Got rmse 115.43657012984599\n",
      "Got rmse 121.59165456252155\n",
      "\n",
      "Epoch 12, Iteration 741, loss = 0.8186\n",
      "Got rmse 101.72918654907865\n",
      "Got rmse 106.82762162374667\n",
      "\n",
      "Epoch 13, Iteration 798, loss = 0.7460\n",
      "Got rmse 98.63260501761982\n",
      "Got rmse 103.59674380997649\n",
      "\n",
      "Epoch 14, Iteration 855, loss = 0.5707\n",
      "Got rmse 90.4206799569039\n",
      "Got rmse 94.71416005422827\n",
      "\n",
      "Epoch 15, Iteration 912, loss = 0.5108\n",
      "Got rmse 84.39291895200343\n",
      "Got rmse 88.48510388555795\n",
      "\n",
      "Epoch 16, Iteration 969, loss = 0.5097\n",
      "Got rmse 83.15739429427471\n",
      "Got rmse 87.01423972154055\n",
      "\n",
      "Epoch 17, Iteration 1026, loss = 0.4839\n",
      "Got rmse 76.64029832513576\n",
      "Got rmse 79.95785762638808\n",
      "\n",
      "Epoch 18, Iteration 1083, loss = 0.3748\n",
      "Got rmse 71.027848551826\n",
      "Got rmse 73.83207188726917\n",
      "\n",
      "Epoch 19, Iteration 1140, loss = 0.4075\n",
      "Got rmse 67.13711185344907\n",
      "Got rmse 69.84667064746121\n",
      "\n",
      "Epoch 20, Iteration 1197, loss = 0.3874\n",
      "Got rmse 67.29774372854843\n",
      "Got rmse 70.0372020819164\n",
      "\n",
      "Epoch 21, Iteration 1254, loss = 0.3926\n",
      "Got rmse 63.26739289120897\n",
      "Got rmse 65.631047111437\n",
      "\n",
      "Epoch 22, Iteration 1311, loss = 0.4314\n",
      "Got rmse 61.89022766104596\n",
      "Got rmse 64.27112096773234\n",
      "\n",
      "Epoch 23, Iteration 1368, loss = 0.3310\n",
      "Got rmse 59.978623815982786\n",
      "Got rmse 62.13246051651468\n",
      "\n",
      "Epoch 24, Iteration 1425, loss = 0.3188\n",
      "Got rmse 57.08878185036718\n",
      "Got rmse 59.1185585291941\n",
      "\n",
      "Epoch 25, Iteration 1482, loss = 0.3325\n",
      "Got rmse 56.00403661469855\n",
      "Got rmse 57.810363379297925\n",
      "\n",
      "Epoch 26, Iteration 1539, loss = 0.3145\n",
      "Got rmse 54.82630783450694\n",
      "Got rmse 56.66330402088637\n",
      "\n",
      "Epoch 27, Iteration 1596, loss = 0.2969\n",
      "Got rmse 54.74904302476961\n",
      "Got rmse 56.446072252855764\n",
      "\n",
      "Epoch 28, Iteration 1653, loss = 0.3400\n",
      "Got rmse 54.004419551798264\n",
      "Got rmse 55.70617203852119\n",
      "\n",
      "Epoch 29, Iteration 1710, loss = 0.2494\n",
      "Got rmse 53.18390198973364\n",
      "Got rmse 54.85617967423001\n",
      "\n",
      "Epoch 30, Iteration 1767, loss = 0.2589\n",
      "Got rmse 51.28775520624545\n",
      "Got rmse 52.8032081193934\n",
      "\n",
      "Epoch 31, Iteration 1824, loss = 0.2429\n",
      "Got rmse 50.76215878407548\n",
      "Got rmse 52.233052195277324\n",
      "\n",
      "Epoch 32, Iteration 1881, loss = 0.2768\n",
      "Got rmse 49.75764668296526\n",
      "Got rmse 51.17588142863407\n",
      "\n",
      "Epoch 33, Iteration 1938, loss = 0.3395\n",
      "Got rmse 50.13375764684307\n",
      "Got rmse 51.503968579665326\n",
      "\n",
      "Epoch 34, Iteration 1995, loss = 0.3120\n",
      "Got rmse 49.372052047485624\n",
      "Got rmse 50.79072798952008\n",
      "\n",
      "Epoch 35, Iteration 2052, loss = 0.2972\n",
      "Got rmse 50.0583303148496\n",
      "Got rmse 51.53334040803073\n",
      "\n",
      "Epoch 36, Iteration 2109, loss = 0.2545\n",
      "Got rmse 48.32158964460416\n",
      "Got rmse 49.62037994196181\n",
      "\n",
      "Epoch 37, Iteration 2166, loss = 0.2216\n",
      "Got rmse 47.909919460225716\n",
      "Got rmse 49.16049696554705\n",
      "\n",
      "Epoch 38, Iteration 2223, loss = 0.2107\n",
      "Got rmse 48.121411027071254\n",
      "Got rmse 49.4226455185758\n",
      "\n",
      "Epoch 39, Iteration 2280, loss = 0.2534\n",
      "Got rmse 48.53302478202143\n",
      "Got rmse 49.807326619256614\n",
      "\n",
      "Epoch 40, Iteration 2337, loss = 0.2131\n",
      "Got rmse 47.10509546892386\n",
      "Got rmse 48.39206383617892\n",
      "\n",
      "Epoch 41, Iteration 2394, loss = 0.1756\n",
      "Got rmse 47.24917719007618\n",
      "Got rmse 48.51103787080572\n",
      "\n",
      "Epoch 42, Iteration 2451, loss = 0.1947\n",
      "Got rmse 46.9895691664386\n",
      "Got rmse 48.340383967763124\n",
      "\n",
      "Epoch 43, Iteration 2508, loss = 0.2716\n",
      "Got rmse 47.01277635878461\n",
      "Got rmse 48.252459822952254\n",
      "\n",
      "Epoch 44, Iteration 2565, loss = 0.2975\n",
      "Got rmse 46.492118450991946\n",
      "Got rmse 47.638171150448336\n",
      "\n",
      "Epoch 45, Iteration 2622, loss = 0.2011\n",
      "Got rmse 46.62058994681622\n",
      "Got rmse 47.89677756293821\n",
      "\n",
      "Epoch 46, Iteration 2679, loss = 0.2443\n",
      "Got rmse 46.53247465516633\n",
      "Got rmse 47.75378831140026\n",
      "\n",
      "Epoch 47, Iteration 2736, loss = 0.1916\n",
      "Got rmse 46.88962702211328\n",
      "Got rmse 48.03493011418441\n",
      "\n",
      "Epoch 48, Iteration 2793, loss = 0.2794\n",
      "Got rmse 45.87881412590108\n",
      "Got rmse 47.01498938327337\n",
      "\n",
      "Epoch 49, Iteration 2850, loss = 0.2487\n",
      "Got rmse 46.5400511599882\n",
      "Got rmse 47.719120603726694\n",
      "\n",
      "Epoch 50, Iteration 2907, loss = 0.2266\n",
      "Got rmse 46.326516168025734\n",
      "Got rmse 47.4445657599816\n",
      "\n",
      "Epoch 51, Iteration 2964, loss = 0.2728\n",
      "Got rmse 46.551848977206056\n",
      "Got rmse 47.72970523135698\n",
      "\n",
      "Epoch 52, Iteration 3021, loss = 0.1882\n",
      "Got rmse 46.40513827586037\n",
      "Got rmse 47.60167657612011\n",
      "\n",
      "Epoch 53, Iteration 3078, loss = 0.2220\n",
      "Got rmse 45.99766167957986\n",
      "Got rmse 47.121462913025006\n",
      "\n",
      "Epoch 54, Iteration 3135, loss = 0.2236\n",
      "Got rmse 45.66236447116473\n",
      "Got rmse 46.729698284580735\n",
      "\n",
      "Epoch 55, Iteration 3192, loss = 0.1652\n",
      "Got rmse 45.50521911494745\n",
      "Got rmse 46.60828816195557\n",
      "\n",
      "Epoch 56, Iteration 3249, loss = 0.2508\n",
      "Got rmse 46.03815110128544\n",
      "Got rmse 47.21687881258393\n",
      "\n",
      "Epoch 57, Iteration 3306, loss = 0.1992\n",
      "Got rmse 46.592322530968936\n",
      "Got rmse 47.846959408503594\n",
      "\n",
      "Epoch 58, Iteration 3363, loss = 0.2254\n",
      "Got rmse 45.61025347814278\n",
      "Got rmse 46.69760806746136\n",
      "\n",
      "Epoch 59, Iteration 3420, loss = 0.1788\n",
      "Got rmse 45.50570807659815\n",
      "Got rmse 46.556259745395316\n",
      "\n",
      "Epoch 60, Iteration 3477, loss = 0.1698\n",
      "Got rmse 45.62508145481873\n",
      "Got rmse 46.687281409840764\n",
      "\n",
      "Epoch 61, Iteration 3534, loss = 0.1998\n",
      "Got rmse 45.52875661843261\n",
      "Got rmse 46.62207341581512\n",
      "\n",
      "Epoch 62, Iteration 3591, loss = 0.2471\n",
      "Got rmse 45.14003013904345\n",
      "Got rmse 46.19288580791205\n",
      "\n",
      "Epoch 63, Iteration 3648, loss = 0.2258\n",
      "Got rmse 45.317207449014106\n",
      "Got rmse 46.38935820901628\n",
      "\n",
      "Epoch 64, Iteration 3705, loss = 0.2439\n",
      "Got rmse 45.45768114604217\n",
      "Got rmse 46.551533874144916\n",
      "\n",
      "Epoch 65, Iteration 3762, loss = 0.2156\n",
      "Got rmse 45.74707796989712\n",
      "Got rmse 46.84457393117117\n",
      "\n",
      "Epoch 66, Iteration 3819, loss = 0.2495\n",
      "Got rmse 45.595497558864075\n",
      "Got rmse 46.71051669237843\n",
      "\n",
      "Epoch 67, Iteration 3876, loss = 0.1737\n",
      "Got rmse 45.47792765043251\n",
      "Got rmse 46.54102443640076\n",
      "\n",
      "Epoch 68, Iteration 3933, loss = 0.2785\n",
      "Got rmse 45.3882129177838\n",
      "Got rmse 46.43840482589512\n",
      "\n",
      "Epoch 69, Iteration 3990, loss = 0.2270\n",
      "Got rmse 45.481407052699964\n",
      "Got rmse 46.53275177908165\n",
      "\n",
      "Epoch 70, Iteration 4047, loss = 0.1617\n",
      "Got rmse 46.00782245390079\n",
      "Got rmse 47.12258612697335\n",
      "\n",
      "Epoch 71, Iteration 4104, loss = 0.2162\n",
      "Got rmse 45.672917815837636\n",
      "Got rmse 46.78838642420714\n",
      "\n",
      "Epoch 72, Iteration 4161, loss = 0.2347\n",
      "Got rmse 45.856163806971765\n",
      "Got rmse 46.97328596474787\n",
      "\n",
      "Epoch 73, Iteration 4218, loss = 0.2243\n",
      "Got rmse 45.2282123026835\n",
      "Got rmse 46.294199202489516\n",
      "\n",
      "Epoch 74, Iteration 4275, loss = 0.2367\n",
      "Got rmse 45.6408917424315\n",
      "Got rmse 46.73615558517193\n",
      "\n",
      "Epoch 75, Iteration 4332, loss = 0.2605\n",
      "Got rmse 45.20192207957659\n",
      "Got rmse 46.247527280585174\n",
      "\n",
      "Epoch 76, Iteration 4389, loss = 0.2065\n",
      "Got rmse 45.02734115636923\n",
      "Got rmse 46.05750417433296\n",
      "\n",
      "Epoch 77, Iteration 4446, loss = 0.2374\n",
      "Got rmse 45.14061245133885\n",
      "Got rmse 46.19560807493348\n",
      "\n",
      "Epoch 78, Iteration 4503, loss = 0.2437\n",
      "Got rmse 45.296236148109244\n",
      "Got rmse 46.370994075666054\n",
      "\n",
      "Epoch 79, Iteration 4560, loss = 0.2027\n",
      "Got rmse 45.363587935219\n",
      "Got rmse 46.41876018713568\n",
      "\n",
      "Epoch 80, Iteration 4617, loss = 0.1798\n",
      "Got rmse 45.45928093231527\n",
      "Got rmse 46.53110381523246\n",
      "\n",
      "Epoch 81, Iteration 4674, loss = 0.1872\n",
      "Got rmse 44.978948127830954\n",
      "Got rmse 45.994973039002325\n",
      "\n",
      "Epoch 82, Iteration 4731, loss = 0.2758\n",
      "Got rmse 45.55990299887759\n",
      "Got rmse 46.6675144235073\n",
      "\n",
      "Epoch 83, Iteration 4788, loss = 0.2162\n",
      "Got rmse 44.85036869146751\n",
      "Got rmse 45.873381834546706\n",
      "\n",
      "Epoch 84, Iteration 4845, loss = 0.2761\n",
      "Got rmse 44.95829381616145\n",
      "Got rmse 45.98941602750472\n",
      "\n",
      "Epoch 85, Iteration 4902, loss = 0.2261\n",
      "Got rmse 44.96115170094746\n",
      "Got rmse 45.95622924016856\n",
      "\n",
      "Epoch 86, Iteration 4959, loss = 0.2064\n",
      "Got rmse 45.07157748602205\n",
      "Got rmse 46.11325711886664\n",
      "\n",
      "Epoch 87, Iteration 5016, loss = 0.2419\n",
      "Got rmse 45.127056961986334\n",
      "Got rmse 46.192093529960935\n",
      "\n",
      "Epoch 88, Iteration 5073, loss = 0.2253\n",
      "Got rmse 44.87303274796507\n",
      "Got rmse 45.88262908774388\n",
      "\n",
      "Epoch 89, Iteration 5130, loss = 0.1866\n",
      "Got rmse 45.10473182699483\n",
      "Got rmse 46.19267254137043\n",
      "\n",
      "Epoch 90, Iteration 5187, loss = 0.2514\n",
      "Got rmse 44.76332042364292\n",
      "Got rmse 45.77161950121908\n",
      "\n",
      "Epoch 91, Iteration 5244, loss = 0.2022\n",
      "Got rmse 44.94359992745684\n",
      "Got rmse 45.96745871992899\n",
      "\n",
      "Epoch 92, Iteration 5301, loss = 0.2428\n",
      "Got rmse 44.73038488562335\n",
      "Got rmse 45.7964326922789\n",
      "\n",
      "Epoch 93, Iteration 5358, loss = 0.1950\n",
      "Got rmse 44.665068265123544\n",
      "Got rmse 45.689128103925974\n",
      "\n",
      "Epoch 94, Iteration 5415, loss = 0.2660\n",
      "Got rmse 44.46672951028503\n",
      "Got rmse 45.48337475266329\n",
      "\n",
      "Epoch 95, Iteration 5472, loss = 0.2021\n",
      "Got rmse 44.6584774358108\n",
      "Got rmse 45.700217041439345\n",
      "\n",
      "Epoch 96, Iteration 5529, loss = 0.2906\n",
      "Got rmse 44.72663916413065\n",
      "Got rmse 45.78292222734874\n",
      "\n",
      "Epoch 97, Iteration 5586, loss = 0.1707\n",
      "Got rmse 44.642393713913826\n",
      "Got rmse 45.64044105843675\n",
      "\n",
      "Epoch 98, Iteration 5643, loss = 0.2814\n",
      "Got rmse 44.98524381375734\n",
      "Got rmse 45.99204924871044\n",
      "\n",
      "Epoch 99, Iteration 5700, loss = 0.2185\n",
      "Got rmse 44.70986682528102\n",
      "Got rmse 45.80034843961847\n",
      "\n",
      "Epoch 100, Iteration 5757, loss = 0.2032\n",
      "Got rmse 44.43953159997996\n",
      "Got rmse 45.544820034861395\n",
      "\n",
      "Epoch 101, Iteration 5814, loss = 0.2124\n",
      "Got rmse 44.268042672644604\n",
      "Got rmse 45.325293969269055\n",
      "\n",
      "Epoch 102, Iteration 5871, loss = 0.1894\n",
      "Got rmse 44.2134961104765\n",
      "Got rmse 45.25282444550609\n",
      "\n",
      "Epoch 103, Iteration 5928, loss = 0.1955\n",
      "Got rmse 44.34758336447113\n",
      "Got rmse 45.399362953768815\n",
      "\n",
      "Epoch 104, Iteration 5985, loss = 0.2346\n",
      "Got rmse 44.20474594806586\n",
      "Got rmse 45.17841892770434\n",
      "\n",
      "Epoch 105, Iteration 6042, loss = 0.2056\n",
      "Got rmse 44.14288005328434\n",
      "Got rmse 45.085172541872666\n",
      "\n",
      "Epoch 106, Iteration 6099, loss = 0.2723\n",
      "Got rmse 44.10078446237733\n",
      "Got rmse 45.13503376750101\n",
      "\n",
      "Epoch 107, Iteration 6156, loss = 0.1684\n",
      "Got rmse 44.11472265277691\n",
      "Got rmse 45.078320148751835\n",
      "\n",
      "Epoch 108, Iteration 6213, loss = 0.2115\n",
      "Got rmse 43.806979461588845\n",
      "Got rmse 44.78352214261165\n",
      "\n",
      "Epoch 109, Iteration 6270, loss = 0.2051\n",
      "Got rmse 43.87441621391375\n",
      "Got rmse 44.849361431552985\n",
      "\n",
      "Epoch 110, Iteration 6327, loss = 0.2079\n",
      "Got rmse 43.79979878681708\n",
      "Got rmse 44.78436521435359\n",
      "\n",
      "Epoch 111, Iteration 6384, loss = 0.2292\n",
      "Got rmse 43.76822430127007\n",
      "Got rmse 44.79652180591775\n",
      "\n",
      "Epoch 112, Iteration 6441, loss = 0.1613\n",
      "Got rmse 43.48994004737828\n",
      "Got rmse 44.43862101421398\n",
      "\n",
      "Epoch 113, Iteration 6498, loss = 0.2210\n",
      "Got rmse 43.64467028053378\n",
      "Got rmse 44.70280247216999\n",
      "\n",
      "Epoch 114, Iteration 6555, loss = 0.1985\n",
      "Got rmse 43.327432168566475\n",
      "Got rmse 44.324994586382516\n",
      "\n",
      "Epoch 115, Iteration 6612, loss = 0.1980\n",
      "Got rmse 43.756942069217864\n",
      "Got rmse 44.698396809277064\n",
      "\n",
      "Epoch 116, Iteration 6669, loss = 0.1559\n",
      "Got rmse 43.224979205686985\n",
      "Got rmse 44.17787967994927\n",
      "\n",
      "Epoch 117, Iteration 6726, loss = 0.2077\n",
      "Got rmse 43.573004066571094\n",
      "Got rmse 44.48121352937792\n",
      "\n",
      "Epoch 118, Iteration 6783, loss = 0.1877\n",
      "Got rmse 43.19563811490267\n",
      "Got rmse 44.16589308520058\n",
      "\n",
      "Epoch 119, Iteration 6840, loss = 0.2439\n",
      "Got rmse 43.030162853519705\n",
      "Got rmse 44.02720220235408\n",
      "\n",
      "Epoch 120, Iteration 6897, loss = 0.1547\n",
      "Got rmse 43.05650415279877\n",
      "Got rmse 44.01224570698296\n",
      "\n",
      "Epoch 121, Iteration 6954, loss = 0.2109\n",
      "Got rmse 42.9614321244027\n",
      "Got rmse 43.80642303895511\n",
      "\n",
      "Epoch 122, Iteration 7011, loss = 0.1679\n",
      "Got rmse 42.93700551560391\n",
      "Got rmse 43.88819603722289\n",
      "\n",
      "Epoch 123, Iteration 7068, loss = 0.1847\n",
      "Got rmse 43.162042692103505\n",
      "Got rmse 44.08750252407435\n",
      "\n",
      "Epoch 124, Iteration 7125, loss = 0.2002\n",
      "Got rmse 43.00073297411994\n",
      "Got rmse 43.9495378543714\n",
      "\n",
      "Epoch 125, Iteration 7182, loss = 0.1423\n",
      "Got rmse 42.866124556026705\n",
      "Got rmse 43.71952473022892\n",
      "\n",
      "Epoch 126, Iteration 7239, loss = 0.2060\n",
      "Got rmse 42.94268589423144\n",
      "Got rmse 43.884266397939555\n",
      "\n",
      "Epoch 127, Iteration 7296, loss = 0.1916\n",
      "Got rmse 42.960449550839016\n",
      "Got rmse 43.93963764651824\n",
      "\n",
      "Epoch 128, Iteration 7353, loss = 0.2407\n",
      "Got rmse 42.46306633065447\n",
      "Got rmse 43.40334410794891\n",
      "\n",
      "Epoch 129, Iteration 7410, loss = 0.2028\n",
      "Got rmse 42.6855447784048\n",
      "Got rmse 43.60513881751199\n",
      "\n",
      "Epoch 130, Iteration 7467, loss = 0.1405\n",
      "Got rmse 42.50945366186113\n",
      "Got rmse 43.4422953526919\n",
      "\n",
      "Epoch 131, Iteration 7524, loss = 0.2059\n",
      "Got rmse 42.480613988216305\n",
      "Got rmse 43.34829447634395\n",
      "\n",
      "Epoch 132, Iteration 7581, loss = 0.2180\n",
      "Got rmse 42.49940147580347\n",
      "Got rmse 43.54602354614356\n",
      "\n",
      "Epoch 133, Iteration 7638, loss = 0.2617\n",
      "Got rmse 42.59072225502212\n",
      "Got rmse 43.44409540161819\n",
      "\n",
      "Epoch 134, Iteration 7695, loss = 0.1804\n",
      "Got rmse 42.4272837989387\n",
      "Got rmse 43.25929723346499\n",
      "\n",
      "Epoch 135, Iteration 7752, loss = 0.1878\n",
      "Got rmse 42.390679944564724\n",
      "Got rmse 43.47986739946001\n",
      "\n",
      "Epoch 136, Iteration 7809, loss = 0.1476\n",
      "Got rmse 42.3536260517388\n",
      "Got rmse 43.23737589945879\n",
      "\n",
      "Epoch 137, Iteration 7866, loss = 0.1385\n",
      "Got rmse 42.25215933553927\n",
      "Got rmse 43.09392638874169\n",
      "\n",
      "Epoch 138, Iteration 7923, loss = 0.2123\n",
      "Got rmse 42.20503835713884\n",
      "Got rmse 43.07994018006803\n",
      "\n",
      "Epoch 139, Iteration 7980, loss = 0.2470\n",
      "Got rmse 41.994215459905035\n",
      "Got rmse 42.88568568927298\n",
      "\n",
      "Epoch 140, Iteration 8037, loss = 0.1757\n",
      "Got rmse 42.126929172359475\n",
      "Got rmse 42.95635081933406\n",
      "\n",
      "Epoch 141, Iteration 8094, loss = 0.1372\n",
      "Got rmse 41.94851912921895\n",
      "Got rmse 42.80305854598265\n",
      "\n",
      "Epoch 142, Iteration 8151, loss = 0.1914\n",
      "Got rmse 42.1556463399389\n",
      "Got rmse 42.9975847289787\n",
      "\n",
      "Epoch 143, Iteration 8208, loss = 0.1533\n",
      "Got rmse 41.942300513101486\n",
      "Got rmse 42.8032906775831\n",
      "\n",
      "Epoch 144, Iteration 8265, loss = 0.1892\n",
      "Got rmse 41.793063711032175\n",
      "Got rmse 42.63401682356778\n",
      "\n",
      "Epoch 145, Iteration 8322, loss = 0.1296\n",
      "Got rmse 41.91217337315866\n",
      "Got rmse 42.74835733542103\n",
      "\n",
      "Epoch 146, Iteration 8379, loss = 0.1432\n",
      "Got rmse 41.81708484963565\n",
      "Got rmse 42.641332236829264\n",
      "\n",
      "Epoch 147, Iteration 8436, loss = 0.1925\n",
      "Got rmse 41.916478164257015\n",
      "Got rmse 42.74586314982408\n",
      "\n",
      "Epoch 148, Iteration 8493, loss = 0.2155\n",
      "Got rmse 42.05066409786366\n",
      "Got rmse 42.82747586110738\n",
      "\n",
      "Epoch 149, Iteration 8550, loss = 0.1545\n",
      "Got rmse 41.96996608247195\n",
      "Got rmse 42.78654604208681\n",
      "\n",
      "Epoch 150, Iteration 8607, loss = 0.1798\n",
      "Got rmse 41.82901853800431\n",
      "Got rmse 42.62530796583262\n",
      "\n",
      "Epoch 151, Iteration 8664, loss = 0.1780\n",
      "Got rmse 41.85389880592197\n",
      "Got rmse 42.72935144780737\n",
      "\n",
      "Epoch 152, Iteration 8721, loss = 0.1633\n",
      "Got rmse 41.84842787244059\n",
      "Got rmse 42.67900915698091\n",
      "\n",
      "Epoch 153, Iteration 8778, loss = 0.1455\n",
      "Got rmse 41.686297963598996\n",
      "Got rmse 42.5736633073481\n",
      "\n",
      "Epoch 154, Iteration 8835, loss = 0.1959\n",
      "Got rmse 41.611408101436695\n",
      "Got rmse 42.478503034394585\n",
      "\n",
      "Epoch 155, Iteration 8892, loss = 0.1472\n",
      "Got rmse 41.82228778987641\n",
      "Got rmse 42.61919618903927\n",
      "\n",
      "Epoch 156, Iteration 8949, loss = 0.1997\n",
      "Got rmse 41.76064627500775\n",
      "Got rmse 42.60947003922456\n",
      "\n",
      "Epoch 157, Iteration 9006, loss = 0.2520\n",
      "Got rmse 41.60053338831133\n",
      "Got rmse 42.45606113406848\n",
      "\n",
      "Epoch 158, Iteration 9063, loss = 0.1917\n",
      "Got rmse 41.89809150988852\n",
      "Got rmse 42.64813922937962\n",
      "\n",
      "Epoch 159, Iteration 9120, loss = 0.1718\n",
      "Got rmse 41.86384948002718\n",
      "Got rmse 42.670696772124074\n",
      "\n",
      "Epoch 160, Iteration 9177, loss = 0.1862\n",
      "Got rmse 41.62094700305001\n",
      "Got rmse 42.477223945395295\n",
      "\n",
      "Epoch 161, Iteration 9234, loss = 0.1460\n",
      "Got rmse 41.51022084940799\n",
      "Got rmse 42.3416455985277\n",
      "\n",
      "Epoch 162, Iteration 9291, loss = 0.1283\n",
      "Got rmse 41.56551163353583\n",
      "Got rmse 42.38870274544016\n",
      "\n",
      "Epoch 163, Iteration 9348, loss = 0.1464\n",
      "Got rmse 41.48079856342348\n",
      "Got rmse 42.283019124852814\n",
      "\n",
      "Epoch 164, Iteration 9405, loss = 0.1861\n",
      "Got rmse 41.479091992342006\n",
      "Got rmse 42.30130609202129\n",
      "\n",
      "Epoch 165, Iteration 9462, loss = 0.1610\n",
      "Got rmse 41.59763151305394\n",
      "Got rmse 42.427262491817764\n",
      "\n",
      "Epoch 166, Iteration 9519, loss = 0.1673\n",
      "Got rmse 41.58027181988427\n",
      "Got rmse 42.3997993681361\n",
      "\n",
      "Epoch 167, Iteration 9576, loss = 0.1311\n",
      "Got rmse 41.6115452084809\n",
      "Got rmse 42.45497182135383\n",
      "\n",
      "Epoch 168, Iteration 9633, loss = 0.1955\n",
      "Got rmse 41.634129731234644\n",
      "Got rmse 42.448226433567704\n",
      "\n",
      "Epoch 169, Iteration 9690, loss = 0.1419\n",
      "Got rmse 41.522040115534345\n",
      "Got rmse 42.2882747599192\n",
      "\n",
      "Epoch 170, Iteration 9747, loss = 0.1679\n",
      "Got rmse 41.58308919698801\n",
      "Got rmse 42.36135863235636\n",
      "\n",
      "Epoch 171, Iteration 9804, loss = 0.1748\n",
      "Got rmse 41.536546773823666\n",
      "Got rmse 42.38872250934218\n",
      "\n",
      "Epoch 172, Iteration 9861, loss = 0.1937\n",
      "Got rmse 41.608649518260776\n",
      "Got rmse 42.39062212272533\n",
      "\n",
      "Epoch 173, Iteration 9918, loss = 0.1623\n",
      "Got rmse 41.473420174815715\n",
      "Got rmse 42.28543255400211\n",
      "\n",
      "Epoch 174, Iteration 9975, loss = 0.1721\n",
      "Got rmse 41.448742849669216\n",
      "Got rmse 42.25586670075747\n",
      "\n",
      "Epoch 175, Iteration 10032, loss = 0.1364\n",
      "Got rmse 41.53391942569813\n",
      "Got rmse 42.31687066038604\n",
      "\n",
      "Epoch 176, Iteration 10089, loss = 0.1392\n",
      "Got rmse 41.44474779123888\n",
      "Got rmse 42.245380165266994\n",
      "\n",
      "Epoch 177, Iteration 10146, loss = 0.1766\n",
      "Got rmse 41.496062357290015\n",
      "Got rmse 42.327293705851254\n",
      "\n",
      "Epoch 178, Iteration 10203, loss = 0.1936\n",
      "Got rmse 41.39032054438726\n",
      "Got rmse 42.21310011275828\n",
      "\n",
      "Epoch 179, Iteration 10260, loss = 0.1580\n",
      "Got rmse 41.53593886125883\n",
      "Got rmse 42.31038542597924\n",
      "\n",
      "Epoch 180, Iteration 10317, loss = 0.1558\n",
      "Got rmse 41.56577579468411\n",
      "Got rmse 42.3472382583872\n",
      "\n",
      "Epoch 181, Iteration 10374, loss = 0.1385\n",
      "Got rmse 41.347004377480985\n",
      "Got rmse 42.1320834640994\n",
      "\n",
      "Epoch 182, Iteration 10431, loss = 0.2227\n",
      "Got rmse 41.38694729137453\n",
      "Got rmse 42.209801912713885\n",
      "\n",
      "Epoch 183, Iteration 10488, loss = 0.1641\n",
      "Got rmse 41.50816609629846\n",
      "Got rmse 42.28655732067756\n",
      "\n",
      "Epoch 184, Iteration 10545, loss = 0.1606\n",
      "Got rmse 41.52206185625046\n",
      "Got rmse 42.29706939594989\n",
      "\n",
      "Epoch 185, Iteration 10602, loss = 0.2227\n",
      "Got rmse 41.40250296108326\n",
      "Got rmse 42.2306541732543\n",
      "\n",
      "Epoch 186, Iteration 10659, loss = 0.1397\n",
      "Got rmse 41.41608461127538\n",
      "Got rmse 42.21260616419978\n",
      "\n",
      "Epoch 187, Iteration 10716, loss = 0.1470\n",
      "Got rmse 41.53392417163463\n",
      "Got rmse 42.33279211854634\n",
      "\n",
      "Epoch 188, Iteration 10773, loss = 0.1858\n",
      "Got rmse 41.382184881855196\n",
      "Got rmse 42.1863067940153\n",
      "\n",
      "Epoch 189, Iteration 10830, loss = 0.1800\n",
      "Got rmse 41.48442435599035\n",
      "Got rmse 42.26919571006859\n",
      "\n",
      "Epoch 190, Iteration 10887, loss = 0.2353\n",
      "Got rmse 41.29525482963302\n",
      "Got rmse 42.0801363940729\n",
      "\n",
      "Epoch 191, Iteration 10944, loss = 0.1388\n",
      "Got rmse 41.41134261304062\n",
      "Got rmse 42.216513036378416\n",
      "\n",
      "Epoch 192, Iteration 11001, loss = 0.1353\n",
      "Got rmse 41.35042745354274\n",
      "Got rmse 42.13103311449019\n",
      "\n",
      "Epoch 193, Iteration 11058, loss = 0.1146\n",
      "Got rmse 41.40870217642873\n",
      "Got rmse 42.20942206469773\n",
      "\n",
      "Epoch 194, Iteration 11115, loss = 0.1361\n",
      "Got rmse 41.39734982958079\n",
      "Got rmse 42.21053631489953\n",
      "\n",
      "Epoch 195, Iteration 11172, loss = 0.1975\n",
      "Got rmse 41.25721984739404\n",
      "Got rmse 42.056758268148265\n",
      "\n",
      "Epoch 196, Iteration 11229, loss = 0.2464\n",
      "Got rmse 41.46572233204765\n",
      "Got rmse 42.26887259874049\n",
      "\n",
      "Epoch 197, Iteration 11286, loss = 0.1457\n",
      "Got rmse 41.424710747166955\n",
      "Got rmse 42.22660518719185\n",
      "\n",
      "Epoch 198, Iteration 11343, loss = 0.2204\n",
      "Got rmse 41.45270277981427\n",
      "Got rmse 42.26163313611529\n",
      "\n",
      "Epoch 199, Iteration 11400, loss = 0.1721\n",
      "Got rmse 41.31891979043363\n",
      "Got rmse 42.11196777762043\n",
      "\n",
      "Epoch 200, Iteration 11457, loss = 0.1737\n",
      "Got rmse 41.47327014831613\n",
      "Got rmse 42.27257395452028\n",
      "\n",
      "Epoch 201, Iteration 11514, loss = 0.2475\n",
      "Got rmse 41.4309358429187\n",
      "Got rmse 42.215186557209066\n",
      "\n",
      "Epoch 202, Iteration 11571, loss = 0.1406\n",
      "Got rmse 41.29214932521943\n",
      "Got rmse 42.07380231923012\n",
      "\n",
      "Epoch 203, Iteration 11628, loss = 0.1524\n",
      "Got rmse 41.253956967510305\n",
      "Got rmse 42.03369917413624\n",
      "\n",
      "Epoch 204, Iteration 11685, loss = 0.1279\n",
      "Got rmse 41.296810874856696\n",
      "Got rmse 42.075905925149264\n",
      "\n",
      "Epoch 205, Iteration 11742, loss = 0.1444\n",
      "Got rmse 41.25050575816954\n",
      "Got rmse 42.056326505077955\n",
      "\n",
      "Epoch 206, Iteration 11799, loss = 0.1515\n",
      "Got rmse 41.32334367750105\n",
      "Got rmse 42.12736231489637\n",
      "\n",
      "Epoch 207, Iteration 11856, loss = 0.1760\n",
      "Got rmse 41.37599656516349\n",
      "Got rmse 42.16120859098391\n",
      "\n",
      "Epoch 208, Iteration 11913, loss = 0.1994\n",
      "Got rmse 41.36427185623861\n",
      "Got rmse 42.1457798018334\n",
      "\n",
      "Epoch 209, Iteration 11970, loss = 0.1110\n",
      "Got rmse 41.40564948697551\n",
      "Got rmse 42.2151544580786\n",
      "\n",
      "Epoch 210, Iteration 12027, loss = 0.1654\n",
      "Got rmse 41.39967485534394\n",
      "Got rmse 42.20558539143602\n",
      "\n",
      "Epoch 211, Iteration 12084, loss = 0.2302\n",
      "Got rmse 41.43469508841018\n",
      "Got rmse 42.22949697285182\n",
      "\n",
      "Epoch 212, Iteration 12141, loss = 0.1867\n",
      "Got rmse 41.2807538921935\n",
      "Got rmse 42.07147413375927\n",
      "\n",
      "Epoch 213, Iteration 12198, loss = 0.1318\n",
      "Got rmse 41.40522855783353\n",
      "Got rmse 42.20691887532714\n",
      "\n",
      "Epoch 214, Iteration 12255, loss = 0.1359\n",
      "Got rmse 41.2776521828577\n",
      "Got rmse 42.072335027075006\n",
      "\n",
      "Epoch 215, Iteration 12312, loss = 0.1453\n",
      "Got rmse 41.34061502833339\n",
      "Got rmse 42.11361907323817\n",
      "\n",
      "Epoch 216, Iteration 12369, loss = 0.1929\n",
      "Got rmse 41.29506918094693\n",
      "Got rmse 42.068101541537885\n",
      "\n",
      "Epoch 217, Iteration 12426, loss = 0.1771\n",
      "Got rmse 41.3874500819304\n",
      "Got rmse 42.19166371954288\n",
      "\n",
      "Epoch 218, Iteration 12483, loss = 0.1465\n",
      "Got rmse 41.25188253823858\n",
      "Got rmse 42.064653772745274\n",
      "\n",
      "Epoch 219, Iteration 12540, loss = 0.2220\n",
      "Got rmse 41.41445227611578\n",
      "Got rmse 42.21287806775417\n",
      "\n",
      "Epoch 220, Iteration 12597, loss = 0.1353\n",
      "Got rmse 41.27979218243158\n",
      "Got rmse 42.07882863346951\n",
      "\n",
      "Epoch 221, Iteration 12654, loss = 0.1830\n",
      "Got rmse 41.373002503569076\n",
      "Got rmse 42.15704163277121\n",
      "\n",
      "Epoch 222, Iteration 12711, loss = 0.1512\n",
      "Got rmse 41.43878138117911\n",
      "Got rmse 42.22894102357638\n",
      "\n",
      "Epoch 223, Iteration 12768, loss = 0.1411\n",
      "Got rmse 41.40127483847736\n",
      "Got rmse 42.2084972539882\n",
      "\n",
      "Epoch 224, Iteration 12825, loss = 0.1939\n",
      "Got rmse 41.35970033477261\n",
      "Got rmse 42.16514108404183\n",
      "\n",
      "Epoch 225, Iteration 12882, loss = 0.1647\n",
      "Got rmse 41.35183887361469\n",
      "Got rmse 42.181037202580235\n",
      "\n",
      "Epoch 226, Iteration 12939, loss = 0.1404\n",
      "Got rmse 41.26372578327559\n",
      "Got rmse 42.066401868453035\n",
      "\n",
      "Epoch 227, Iteration 12996, loss = 0.1891\n",
      "Got rmse 41.29243900808338\n",
      "Got rmse 42.09745978736374\n",
      "\n",
      "Epoch 228, Iteration 13053, loss = 0.1565\n",
      "Got rmse 41.2980624502529\n",
      "Got rmse 42.105744249153545\n",
      "\n",
      "Epoch 229, Iteration 13110, loss = 0.1176\n",
      "Got rmse 41.30277995823407\n",
      "Got rmse 42.083578754592615\n",
      "\n",
      "Epoch 230, Iteration 13167, loss = 0.2248\n",
      "Got rmse 41.18161460691006\n",
      "Got rmse 41.970566074039525\n",
      "\n",
      "Epoch 231, Iteration 13224, loss = 0.1450\n",
      "Got rmse 41.350832853109544\n",
      "Got rmse 42.12033919030776\n",
      "\n",
      "Epoch 232, Iteration 13281, loss = 0.1959\n",
      "Got rmse 41.26742496059142\n",
      "Got rmse 42.03271801319644\n",
      "\n",
      "Epoch 233, Iteration 13338, loss = 0.1302\n",
      "Got rmse 41.294497419361534\n",
      "Got rmse 42.13443845009918\n",
      "\n",
      "Epoch 234, Iteration 13395, loss = 0.1370\n",
      "Got rmse 41.35091195337879\n",
      "Got rmse 42.142232148042595\n",
      "\n",
      "Epoch 235, Iteration 13452, loss = 0.1928\n",
      "Got rmse 41.25645249437508\n",
      "Got rmse 42.06818177650236\n",
      "\n",
      "Epoch 236, Iteration 13509, loss = 0.1902\n",
      "Got rmse 41.22957497510094\n",
      "Got rmse 42.029628958723684\n",
      "\n",
      "Epoch 237, Iteration 13566, loss = 0.1271\n",
      "Got rmse 41.32054798797546\n",
      "Got rmse 42.105830389166854\n",
      "\n",
      "Epoch 238, Iteration 13623, loss = 0.2423\n",
      "Got rmse 41.339878237150955\n",
      "Got rmse 42.151479861365694\n",
      "\n",
      "Epoch 239, Iteration 13680, loss = 0.1639\n",
      "Got rmse 41.22924352771403\n",
      "Got rmse 41.98853705330809\n",
      "\n",
      "Epoch 240, Iteration 13737, loss = 0.1686\n",
      "Got rmse 41.440180871433164\n",
      "Got rmse 42.252588432486945\n",
      "\n",
      "Epoch 241, Iteration 13794, loss = 0.2246\n",
      "Got rmse 41.21047153810563\n",
      "Got rmse 42.017192653922876\n",
      "\n",
      "Epoch 242, Iteration 13851, loss = 0.1717\n",
      "Got rmse 41.322476992427355\n",
      "Got rmse 42.09865817908802\n",
      "\n",
      "Epoch 243, Iteration 13908, loss = 0.2368\n",
      "Got rmse 41.30706430467691\n",
      "Got rmse 42.13243630247719\n",
      "\n",
      "Epoch 244, Iteration 13965, loss = 0.2112\n",
      "Got rmse 41.16653247422618\n",
      "Got rmse 41.97231124952328\n",
      "\n",
      "Epoch 245, Iteration 14022, loss = 0.2049\n",
      "Got rmse 41.24465137469338\n",
      "Got rmse 42.043978878891686\n",
      "\n",
      "Epoch 246, Iteration 14079, loss = 0.1754\n",
      "Got rmse 41.312353998473675\n",
      "Got rmse 42.125871683522846\n",
      "\n",
      "Epoch 247, Iteration 14136, loss = 0.1610\n",
      "Got rmse 41.306431784658415\n",
      "Got rmse 42.13489797873749\n",
      "\n",
      "Epoch 248, Iteration 14193, loss = 0.2074\n",
      "Got rmse 41.254070631354615\n",
      "Got rmse 42.02571048330923\n",
      "\n",
      "Epoch 249, Iteration 14250, loss = 0.1163\n",
      "Got rmse 41.126948192251525\n",
      "Got rmse 41.93763764402277\n",
      "\n",
      "Epoch 250, Iteration 14307, loss = 0.1601\n",
      "Got rmse 41.18987663105076\n",
      "Got rmse 41.97614115953464\n",
      "\n",
      "Epoch 251, Iteration 14364, loss = 0.1554\n",
      "Got rmse 41.15123354787098\n",
      "Got rmse 41.948298094191465\n",
      "\n",
      "Epoch 252, Iteration 14421, loss = 0.1483\n",
      "Got rmse 41.20321491304482\n",
      "Got rmse 41.98383439548387\n",
      "\n",
      "Epoch 253, Iteration 14478, loss = 0.1659\n",
      "Got rmse 41.18213087644046\n",
      "Got rmse 41.97646378934409\n",
      "\n",
      "Epoch 254, Iteration 14535, loss = 0.1727\n",
      "Got rmse 41.19338837577307\n",
      "Got rmse 41.99567461490552\n",
      "\n",
      "Epoch 255, Iteration 14592, loss = 0.1559\n",
      "Got rmse 41.10475343866278\n",
      "Got rmse 41.889060251297565\n",
      "\n",
      "Epoch 256, Iteration 14649, loss = 0.1538\n",
      "Got rmse 41.24886856446829\n",
      "Got rmse 42.012942588910725\n",
      "\n",
      "Epoch 257, Iteration 14706, loss = 0.1829\n",
      "Got rmse 41.155089422625245\n",
      "Got rmse 41.94360218413799\n",
      "\n",
      "Epoch 258, Iteration 14763, loss = 0.1270\n",
      "Got rmse 41.20615757280985\n",
      "Got rmse 41.99753897304793\n",
      "\n",
      "Epoch 259, Iteration 14820, loss = 0.2319\n",
      "Got rmse 41.27123113499577\n",
      "Got rmse 42.11388140517377\n",
      "\n",
      "Epoch 260, Iteration 14877, loss = 0.1793\n",
      "Got rmse 41.17695171291222\n",
      "Got rmse 41.94641649438882\n",
      "\n",
      "Epoch 261, Iteration 14934, loss = 0.2672\n",
      "Got rmse 41.18891796270869\n",
      "Got rmse 42.085140363615785\n",
      "\n",
      "Epoch 262, Iteration 14991, loss = 0.1328\n",
      "Got rmse 41.09161643287317\n",
      "Got rmse 41.88053566754082\n",
      "\n",
      "Epoch 263, Iteration 15048, loss = 0.1685\n",
      "Got rmse 41.09139903879398\n",
      "Got rmse 41.859965682314076\n",
      "\n",
      "Epoch 264, Iteration 15105, loss = 0.2140\n",
      "Got rmse 41.12036279736469\n",
      "Got rmse 41.93294492166737\n",
      "\n",
      "Epoch 265, Iteration 15162, loss = 0.1628\n",
      "Got rmse 41.16938315094664\n",
      "Got rmse 41.97479172203525\n",
      "\n",
      "Epoch 266, Iteration 15219, loss = 0.2044\n",
      "Got rmse 41.051654930592925\n",
      "Got rmse 41.849210035554535\n",
      "\n",
      "Epoch 267, Iteration 15276, loss = 0.1684\n",
      "Got rmse 41.16735535302591\n",
      "Got rmse 41.94249542450327\n",
      "\n",
      "Epoch 268, Iteration 15333, loss = 0.1616\n",
      "Got rmse 41.11841706878041\n",
      "Got rmse 41.90395884768916\n",
      "\n",
      "Epoch 269, Iteration 15390, loss = 0.1382\n",
      "Got rmse 41.156898310984076\n",
      "Got rmse 41.94213876626372\n",
      "\n",
      "Epoch 270, Iteration 15447, loss = 0.1326\n",
      "Got rmse 41.060599022826494\n",
      "Got rmse 41.854441783685495\n",
      "\n",
      "Epoch 271, Iteration 15504, loss = 0.1560\n",
      "Got rmse 41.2753883348023\n",
      "Got rmse 42.078702456417936\n",
      "\n",
      "Epoch 272, Iteration 15561, loss = 0.1915\n",
      "Got rmse 41.10950454751265\n",
      "Got rmse 41.91363997278135\n",
      "\n",
      "Epoch 273, Iteration 15618, loss = 0.1149\n",
      "Got rmse 41.10558809832698\n",
      "Got rmse 41.86213995255505\n",
      "\n",
      "Epoch 274, Iteration 15675, loss = 0.1467\n",
      "Got rmse 41.212109107428276\n",
      "Got rmse 41.952339835490754\n",
      "\n",
      "Epoch 275, Iteration 15732, loss = 0.1315\n",
      "Got rmse 41.172919163659245\n",
      "Got rmse 41.917781106124025\n",
      "\n",
      "Epoch 276, Iteration 15789, loss = 0.1777\n",
      "Got rmse 40.99860913475835\n",
      "Got rmse 41.81565273381534\n",
      "\n",
      "Epoch 277, Iteration 15846, loss = 0.1473\n",
      "Got rmse 41.00286445153716\n",
      "Got rmse 41.841346401401175\n",
      "\n",
      "Epoch 278, Iteration 15903, loss = 0.2156\n",
      "Got rmse 41.11807450022154\n",
      "Got rmse 41.89761558669132\n",
      "\n",
      "Epoch 279, Iteration 15960, loss = 0.1716\n",
      "Got rmse 41.05827607992738\n",
      "Got rmse 41.83970496332805\n",
      "\n",
      "Epoch 280, Iteration 16017, loss = 0.1471\n",
      "Got rmse 40.99204691262069\n",
      "Got rmse 41.78000359921581\n",
      "\n",
      "Epoch 281, Iteration 16074, loss = 0.2083\n",
      "Got rmse 41.119459074282155\n",
      "Got rmse 41.87693362196141\n",
      "\n",
      "Epoch 282, Iteration 16131, loss = 0.2018\n",
      "Got rmse 41.13971694643763\n",
      "Got rmse 41.91450911326002\n",
      "\n",
      "Epoch 283, Iteration 16188, loss = 0.2231\n",
      "Got rmse 41.122262349731315\n",
      "Got rmse 41.90353180850702\n",
      "\n",
      "Epoch 284, Iteration 16245, loss = 0.1951\n",
      "Got rmse 40.9946982873555\n",
      "Got rmse 41.76654389511089\n",
      "\n",
      "Epoch 285, Iteration 16302, loss = 0.1482\n",
      "Got rmse 40.964090977896255\n",
      "Got rmse 41.71933671563816\n",
      "\n",
      "Epoch 286, Iteration 16359, loss = 0.2616\n",
      "Got rmse 41.12245724958958\n",
      "Got rmse 41.932666069761616\n",
      "\n",
      "Epoch 287, Iteration 16416, loss = 0.1525\n",
      "Got rmse 40.95076574034525\n",
      "Got rmse 41.72876775235958\n",
      "\n",
      "Epoch 288, Iteration 16473, loss = 0.1645\n",
      "Got rmse 40.94180721831304\n",
      "Got rmse 41.715617309002\n",
      "\n",
      "Epoch 289, Iteration 16530, loss = 0.1655\n",
      "Got rmse 41.001705581193455\n",
      "Got rmse 41.76244349397445\n",
      "\n",
      "Epoch 290, Iteration 16587, loss = 0.1380\n",
      "Got rmse 41.078267087511925\n",
      "Got rmse 41.83294005675159\n",
      "\n",
      "Epoch 291, Iteration 16644, loss = 0.1291\n",
      "Got rmse 40.99046162452186\n",
      "Got rmse 41.79385461763161\n",
      "\n",
      "Epoch 292, Iteration 16701, loss = 0.1844\n",
      "Got rmse 40.967028037494195\n",
      "Got rmse 41.76667526289847\n",
      "\n",
      "Epoch 293, Iteration 16758, loss = 0.1455\n",
      "Got rmse 41.00506708294513\n",
      "Got rmse 41.7906227281721\n",
      "\n",
      "Epoch 294, Iteration 16815, loss = 0.1314\n",
      "Got rmse 41.10304208334165\n",
      "Got rmse 41.895230710647574\n",
      "\n",
      "Epoch 295, Iteration 16872, loss = 0.1680\n",
      "Got rmse 40.97024766154588\n",
      "Got rmse 41.735546580674196\n",
      "\n",
      "Epoch 296, Iteration 16929, loss = 0.1429\n",
      "Got rmse 40.94301399916936\n",
      "Got rmse 41.710955347901866\n",
      "\n",
      "Epoch 297, Iteration 16986, loss = 0.1954\n",
      "Got rmse 41.00533692725895\n",
      "Got rmse 41.77533524680622\n",
      "\n",
      "Epoch 298, Iteration 17043, loss = 0.2198\n",
      "Got rmse 40.910227092503256\n",
      "Got rmse 41.69190160040284\n",
      "\n",
      "Epoch 299, Iteration 17100, loss = 0.1761\n",
      "Got rmse 41.017641827859656\n",
      "Got rmse 41.78007380389417\n",
      "\n",
      "Epoch 300, Iteration 17157, loss = 0.1708\n",
      "Got rmse 40.991331905943376\n",
      "Got rmse 41.76232015446135\n",
      "\n",
      "Epoch 301, Iteration 17214, loss = 0.1960\n",
      "Got rmse 40.94964983027679\n",
      "Got rmse 41.71094317325268\n",
      "\n",
      "Epoch 302, Iteration 17271, loss = 0.1930\n",
      "Got rmse 41.07139242534628\n",
      "Got rmse 41.836248769165756\n",
      "\n",
      "Epoch 303, Iteration 17328, loss = 0.1566\n",
      "Got rmse 40.96081673845658\n",
      "Got rmse 41.75190621303012\n",
      "\n",
      "Epoch 304, Iteration 17385, loss = 0.1580\n",
      "Got rmse 41.00430186245213\n",
      "Got rmse 41.77756601820861\n",
      "\n",
      "Epoch 305, Iteration 17442, loss = 0.1147\n",
      "Got rmse 40.92708602662339\n",
      "Got rmse 41.69786672811173\n",
      "\n",
      "Epoch 306, Iteration 17499, loss = 0.1389\n",
      "Got rmse 40.944855975244664\n",
      "Got rmse 41.705428479281984\n",
      "\n",
      "Epoch 307, Iteration 17556, loss = 0.1798\n",
      "Got rmse 40.959353897790194\n",
      "Got rmse 41.714850523332956\n",
      "\n",
      "Epoch 308, Iteration 17613, loss = 0.1655\n",
      "Got rmse 40.98139811234393\n",
      "Got rmse 41.74973097386691\n",
      "\n",
      "Epoch 309, Iteration 17670, loss = 0.1833\n",
      "Got rmse 41.05980666857338\n",
      "Got rmse 41.86411141008216\n",
      "\n",
      "Epoch 310, Iteration 17727, loss = 0.1140\n",
      "Got rmse 40.91844801281381\n",
      "Got rmse 41.69414014805252\n",
      "\n",
      "Epoch 311, Iteration 17784, loss = 0.1837\n",
      "Got rmse 40.945019491094314\n",
      "Got rmse 41.723389422041215\n",
      "\n",
      "Epoch 312, Iteration 17841, loss = 0.1411\n",
      "Got rmse 40.97401995589279\n",
      "Got rmse 41.735110212510314\n",
      "\n",
      "Epoch 313, Iteration 17898, loss = 0.1816\n",
      "Got rmse 40.89131926121608\n",
      "Got rmse 41.67701881200593\n",
      "\n",
      "Epoch 314, Iteration 17955, loss = 0.1584\n",
      "Got rmse 40.96961472377786\n",
      "Got rmse 41.74424431890604\n",
      "\n",
      "Epoch 315, Iteration 18012, loss = 0.1687\n",
      "Got rmse 40.968694505832765\n",
      "Got rmse 41.7353323218344\n",
      "\n",
      "Epoch 316, Iteration 18069, loss = 0.1616\n",
      "Got rmse 40.97387885298083\n",
      "Got rmse 41.74312135974167\n",
      "\n",
      "Epoch 317, Iteration 18126, loss = 0.1998\n",
      "Got rmse 40.89291263025935\n",
      "Got rmse 41.67953713301378\n",
      "\n",
      "Epoch 318, Iteration 18183, loss = 0.1407\n",
      "Got rmse 40.93702230351735\n",
      "Got rmse 41.7346745817859\n",
      "\n",
      "Epoch 319, Iteration 18240, loss = 0.1854\n",
      "Got rmse 40.94680535259632\n",
      "Got rmse 41.702231009011825\n",
      "\n",
      "Epoch 320, Iteration 18297, loss = 0.1752\n",
      "Got rmse 40.95838285095625\n",
      "Got rmse 41.73216652570344\n",
      "\n",
      "Epoch 321, Iteration 18354, loss = 0.2168\n",
      "Got rmse 41.09445855605853\n",
      "Got rmse 41.88440499458417\n",
      "\n",
      "Epoch 322, Iteration 18411, loss = 0.1561\n",
      "Got rmse 40.972180046118964\n",
      "Got rmse 41.737150699244765\n",
      "\n",
      "Epoch 323, Iteration 18468, loss = 0.1542\n",
      "Got rmse 41.09728839066029\n",
      "Got rmse 41.88903105357972\n",
      "\n",
      "Epoch 324, Iteration 18525, loss = 0.2150\n",
      "Got rmse 40.909405969750715\n",
      "Got rmse 41.6747883982639\n",
      "\n",
      "Epoch 325, Iteration 18582, loss = 0.1418\n",
      "Got rmse 40.98789400107818\n",
      "Got rmse 41.745375269543366\n",
      "\n",
      "Epoch 326, Iteration 18639, loss = 0.1930\n",
      "Got rmse 41.04341629885274\n",
      "Got rmse 41.80002798495246\n",
      "\n",
      "Epoch 327, Iteration 18696, loss = 0.1942\n",
      "Got rmse 40.974331709189336\n",
      "Got rmse 41.745422042003874\n",
      "\n",
      "Epoch 328, Iteration 18753, loss = 0.1111\n",
      "Got rmse 40.942248480990095\n",
      "Got rmse 41.69999828765226\n",
      "\n",
      "Epoch 329, Iteration 18810, loss = 0.1327\n",
      "Got rmse 40.80992546095998\n",
      "Got rmse 41.58445105026389\n",
      "\n",
      "Epoch 330, Iteration 18867, loss = 0.2732\n",
      "Got rmse 40.915053799402166\n",
      "Got rmse 41.6752663856813\n",
      "\n",
      "Epoch 331, Iteration 18924, loss = 0.1511\n",
      "Got rmse 40.965905479420684\n",
      "Got rmse 41.716425545737835\n",
      "\n",
      "Epoch 332, Iteration 18981, loss = 0.1975\n",
      "Got rmse 40.87547129416445\n",
      "Got rmse 41.658261595967105\n",
      "\n",
      "Epoch 333, Iteration 19038, loss = 0.1480\n",
      "Got rmse 40.96558470600856\n",
      "Got rmse 41.703554487762396\n",
      "\n",
      "Epoch 334, Iteration 19095, loss = 0.1439\n",
      "Got rmse 40.86007672704681\n",
      "Got rmse 41.64836940171826\n",
      "\n",
      "Epoch 335, Iteration 19152, loss = 0.1811\n",
      "Got rmse 40.97291983957945\n",
      "Got rmse 41.75013052056339\n",
      "\n",
      "Epoch 336, Iteration 19209, loss = 0.2316\n",
      "Got rmse 40.99088110433383\n",
      "Got rmse 41.794520717168055\n",
      "\n",
      "Epoch 337, Iteration 19266, loss = 0.1722\n",
      "Got rmse 40.9089805052467\n",
      "Got rmse 41.66329151413492\n",
      "\n",
      "Epoch 338, Iteration 19323, loss = 0.2535\n",
      "Got rmse 40.97073063456483\n",
      "Got rmse 41.7245958085327\n",
      "\n",
      "Epoch 339, Iteration 19380, loss = 0.1609\n",
      "Got rmse 40.968472289015025\n",
      "Got rmse 41.73161384916676\n",
      "\n",
      "Epoch 340, Iteration 19437, loss = 0.1301\n",
      "Got rmse 40.905159407281694\n",
      "Got rmse 41.66659491493208\n",
      "\n",
      "Epoch 341, Iteration 19494, loss = 0.1640\n",
      "Got rmse 40.87126696201487\n",
      "Got rmse 41.663078306909284\n",
      "\n",
      "Epoch 342, Iteration 19551, loss = 0.1305\n",
      "Got rmse 40.79408482003093\n",
      "Got rmse 41.57100636938296\n",
      "\n",
      "Epoch 343, Iteration 19608, loss = 0.2460\n",
      "Got rmse 41.0317066512456\n",
      "Got rmse 41.822763897966716\n",
      "\n",
      "Epoch 344, Iteration 19665, loss = 0.1602\n",
      "Got rmse 40.89864331222951\n",
      "Got rmse 41.676772739509865\n",
      "\n",
      "Epoch 345, Iteration 19722, loss = 0.1520\n",
      "Got rmse 40.83156910799732\n",
      "Got rmse 41.593681151531506\n",
      "\n",
      "Epoch 346, Iteration 19779, loss = 0.1844\n",
      "Got rmse 40.87895964079367\n",
      "Got rmse 41.64630540378394\n",
      "\n",
      "Epoch 347, Iteration 19836, loss = 0.1537\n",
      "Got rmse 40.89808452490326\n",
      "Got rmse 41.66111142206268\n",
      "\n",
      "Epoch 348, Iteration 19893, loss = 0.1334\n",
      "Got rmse 40.95291404375296\n",
      "Got rmse 41.730647247947445\n",
      "\n",
      "Epoch 349, Iteration 19950, loss = 0.2000\n",
      "Got rmse 40.84576882576438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [07:21<00:00, 441.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got rmse 41.61649201875419\n",
      "\n",
      "training stop at epoch: 349\n",
      "training stop at epoch: tensor(0.9888, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Neural_network import Generative_net, ResidualEMNSBlock_3d, BigBlock, weight_init, eMNS_Dataset\n",
    "from Training_loop import train_part_GM,get_mean_of_dataloader\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 16\n",
    "# construct dataset\n",
    "dataset = eMNS_Dataset(\n",
    "    train_x=current_norm,\n",
    "    train_y=Bfield_norm\n",
    ")\n",
    "###############################################\n",
    "# Config the neural network\n",
    "###############################################\n",
    "num_input = 8\n",
    "output_shape = (3,16,16,16)\n",
    "SB_args = (64,64,1,4) # (Cin, Cout, num_repeat, num_block)\n",
    "BB_args = (2,1) # (scale_factor, num_block)\n",
    "SB_block = ResidualEMNSBlock_3d \n",
    "BB_block = BigBlock\n",
    "DF = False # whether using divergence free model\n",
    "\n",
    "Generative_network = Generative_net(SB_args, BB_args, SB_block, BB_block, num_input=num_input, output_shape= output_shape)\n",
    "epochs = 350\n",
    "learning_rate_decay = .5\n",
    "learning_rates = [1e-5]\n",
    "RMSE_lr = []\n",
    "schedule = []\n",
    "linear_lr = False\n",
    "weight_decays = [1e-3]\n",
    "\n",
    "train_percents = np.arange(1.0,1.01,0.1)\n",
    "RMSE_history_end = np.zeros(len(train_percents))\n",
    "RMSE_val_history_end = np.zeros(len(train_percents))\n",
    "loss_history_end = np.zeros(len(train_percents))\n",
    "iter_history_end = np.zeros(len(train_percents))\n",
    "mse_history_end = np.zeros(len(train_percents))\n",
    "mse_val_history_end = np.zeros(len(train_percents))\n",
    "train_stop_epoch = np.zeros(len(train_percents))\n",
    "\n",
    "################################################\n",
    "# Train the neural network\n",
    "################################################\n",
    "index=0\n",
    "for train_percent in train_percents:\n",
    "    epoch_stop = 0\n",
    "    print('train_percent',train_percent)\n",
    "    for learning_rate in tqdm(learning_rates):\n",
    "        for weight_decay in weight_decays:\n",
    "\n",
    "            # split the dataset to train, validation, test\n",
    "            train_set, valid_set = torch.utils.data.random_split(dataset, [0.9,0.1])\n",
    "\n",
    "            #Using Dataloader for batch train\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)\n",
    "            valid_loader = torch.utils.data.DataLoader(dataset=valid_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "            get_mean_of_dataloader(valid_loader,model=Generative_network,device=device)\n",
    "            print(\"----------------------------\")\n",
    "            \n",
    "            print(\"----------------------------\")\n",
    "            # test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "            Generative_network.apply(weight_init)\n",
    "            optimizer = torch.optim.Adam([{'params':Generative_network.parameters()}], lr=learning_rate, weight_decay= weight_decay, betas=(0.5,0.99))\n",
    "            RMSE_history, RMSE_val_history, loss_history, iter_history, mse_history, mse_val_history,epoch_stop,Rsquare= train_part_GM(\n",
    "                model=Generative_network, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, epochs=epochs, \n",
    "                learning_rate_decay=learning_rate_decay, schedule=schedule, weight_decay=weight_decay, DF=DF,verbose=False, device=device, maxB=MaxB[0,:], minB=MinB[0,:],\n",
    "                lr_max=learning_rate, lr_min=2.5e-7,max_epoch=epochs, linear_lr=linear_lr)\n",
    "        \n",
    "        RMSE_lr.append(RMSE_val_history[epoch_stop].item())\n",
    "    \n",
    "    #save RMSE and loss after early stopping\n",
    "    RMSE_history_end[index] = RMSE_history[epoch_stop]\n",
    "    RMSE_val_history_end[index]= RMSE_val_history[epoch_stop]\n",
    "    loss_history_end[index] = loss_history[epoch_stop]\n",
    "    iter_history_end[index] = iter_history[epoch_stop]\n",
    "    mse_history_end[index] = mse_history[epoch_stop]\n",
    "    mse_val_history_end[index] = mse_val_history[epoch_stop]\n",
    "    index=index+1\n",
    "    print('training stop at epoch:',epoch_stop)\n",
    "    print('training stop at epoch:',Rsquare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Generative_network, 'EMS_CNN_ETH.pt')\t# 这里会存储迄今最优模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(RMSE_lr)\n",
    "print(learning_rates)\n",
    "print(RMSE_lr[0],learning_rates[0])\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(learning_rates,RMSE_lr)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ave_site = 5\n",
    "ave_kernel = 1/ave_site*np.ones(ave_site)\n",
    "loss_history_conv = np.convolve(loss_history.numpy(),ave_kernel,'same')\n",
    "\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(iter_history,loss_history,'-o')\n",
    "plt.plot(iter_history,loss_history_conv,'-*')\n",
    "plt.legend(['loss','loss_conv'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n",
    "\n",
    "plt.title('Train and Val RMSE(sample_num=1000)')\n",
    "plt.plot(iter_history[0:epoch_stop],RMSE_history[0:epoch_stop],'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],RMSE_val_history[0:epoch_stop],'-*')\n",
    "# plt.plot(2e-5*np.arange(epoch_stop),RMSE_history[0:epoch_stop]*1000,'-o')\n",
    "# plt.plot(2e-5*np.arange(epoch_stop),RMSE_val_history[0:epoch_stop]*1000,'-*')\n",
    "# plt.ylim([15,20])\n",
    "plt.legend(['train CNN','val CNN'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('RMSE(mT)')\n",
    "plt.ylim([0,100])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Train and Val loss(sample_num=1000)')\n",
    "plt.plot(iter_history[0:epoch_stop],mse_history[0:epoch_stop]*1e6,'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],mse_val_history[0:epoch_stop]*1e6,'-*')\n",
    "plt.legend(['train CNN','val CNN'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('mse(mT^2)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(epoch_stop)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
