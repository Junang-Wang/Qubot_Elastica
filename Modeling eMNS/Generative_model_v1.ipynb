{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook employs a fully connective neural network(FC) or its alias artificial neural network (ANN) to learn the mapping between input current configuration between output magnetic field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "if torch.cuda.device_count():\n",
    "    device = 'cuda'\n",
    "    print('Good to go')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 21, 21, 21])\n",
      "current shape torch.Size([10, 12])\n",
      "Bfield shape torch.Size([10, 3, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "from ReadData import ReadCurrentAndField_CNN, add_gaussian_noise\n",
    "import glob\n",
    "import os \n",
    "\n",
    "# TODO zhoujing edit this Data loading \n",
    "# print(os.getcwd())\n",
    "foldername=\"./Data/\"\n",
    "filepattern = \"MagneticField[0-9]*.txt\"\n",
    "train_file_num= 10\n",
    "noise = 0.05\n",
    "#data = ReadFolder(foldername,filepattern)\n",
    "current,data = ReadCurrentAndField_CNN (foldername,filepattern,train_file_num)\n",
    "\n",
    "fileList = glob.glob(foldername+filepattern)\n",
    "position = data[:,0:3,2:18,2:18,2:18]\n",
    "Bfield = data[:,3:,2:18,2:18,2:18]\n",
    "\n",
    "# print(fileList)\n",
    "print(data.shape)\n",
    "print('current shape', current.shape)\n",
    "print('Bfield shape', Bfield.shape)\n",
    "# current = add_gaussian_noise(current,noise=noise)\n",
    "# Bfield = add_gaussian_noise(Bfield,noise=noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.0000000745e-02, -5.0000000745e-02, -5.0000000745e-02, 4.2985486798e-03,\n",
      "        1.7197148874e-02, -1.9071470946e-02])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(data[2,:,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 16, 16, 16])\n",
      "tensor(-8.8250178099e-01)\n",
      "tensor(2.0021591627e-04)\n",
      "tensor(1.4149766922e+01)\n"
     ]
    }
   ],
   "source": [
    "print(Bfield.shape)\n",
    "print(Bfield.mean()*1e3)\n",
    "print(Bfield.var())\n",
    "print(Bfield.std()*1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3859445006e-02],\n",
      "        [3.6636061966e-02],\n",
      "        [2.6710866019e-02]])\n",
      "tensor([[-3.9988111705e-02],\n",
      "        [-3.4502133727e-02],\n",
      "        [-4.1056130081e-02]])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#data normalization\n",
    "#find min and max value of input position and Bfield\n",
    "max_current, max_current_index = torch.max(current, dim=0, keepdim=True)\n",
    "# print(max_current)\n",
    "min_current, min_current_index = torch.min(current, dim=0, keepdim=True)\n",
    "# print(min_current)\n",
    "\n",
    "max_Bfield, max_Bfield_index = torch.max(Bfield.transpose(0,1).reshape(3,-1), dim=1, keepdim=True)\n",
    "print(max_Bfield)\n",
    "min_Bfield, min_Bfield_index = torch.min(Bfield.transpose(0,1).reshape(3,-1), dim=1, keepdim=True)\n",
    "print(min_Bfield)\n",
    "\n",
    "dimB = Bfield.shape\n",
    "dimc = current.shape\n",
    "print(min_current.shape)\n",
    "print(min_Bfield.shape)\n",
    "\n",
    "minB=min_Bfield.expand(3,int(Bfield.numel()/3)).reshape(3,dimB[0],dimB[2],dimB[3],dimB[4]).transpose(0,1)\n",
    "maxB=max_Bfield.expand(3,int(Bfield.numel()/3)).reshape(3,dimB[0],dimB[2],dimB[3],dimB[4]).transpose(0,1)\n",
    "\n",
    "ave_current=0.5*(max_current.expand(dimc[0],dimc[1])+min_current.expand(dimc[0],dimc[1]))\n",
    "diff_current=0.5*(max_current.expand(dimc[0],dimc[1])-min_current.expand(dimc[0],dimc[1]))\n",
    "\n",
    "current_norm = (current-ave_current)/diff_current\n",
    "Bfield_norm = (Bfield-(minB+maxB)*0.5)/(0.5*(maxB-minB))\n",
    "\n",
    "print(min_current.shape)\n",
    "print(max_current.shape)\n",
    "print(min_Bfield.shape)\n",
    "print(max_Bfield.shape)\n",
    "\n",
    "torch.save(min_current, \"./normalize_data/cnn_min_current.pt\")\n",
    "torch.save(max_current, \"./normalize_data/cnn_max_current.pt\")\n",
    "torch.save(min_Bfield, \"./normalize_data/cnn_min_Bfield.pt\")\n",
    "torch.save(max_Bfield, \"./normalize_data/cnn_max_Bfield.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_network import Generative_net, ResidualEMNSBlock_3d, BigBlock, weight_init, eMNS_Dataset\n",
    "num_input = 12\n",
    "output_shape = (3,16,16,16)\n",
    "SB_args = (64,64,4,1) # (Cin, Cout, num_block)\n",
    "BB_args = (2,2) # (scale_factor, num_block)\n",
    "SB_block = ResidualEMNSBlock_3d \n",
    "BB_block = BigBlock\n",
    "\n",
    "Generative_network = Generative_net(SB_args, BB_args, SB_block, BB_block, num_input=num_input, output_shape= output_shape)\n",
    "print(Generative_network)\n",
    "\n",
    "print(maxB.shape)\n",
    "print(maxB[0,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "MaxB=maxB.cuda(0)\n",
    "MinB=minB.cuda(0)\n",
    "print(MaxB.device)\n",
    "print(MinB.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNeural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generative_net, ResidualEMNSBlock_3d, BigBlock, weight_init, eMNS_Dataset,Generative_net_test\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTraining_loop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_part_GM,get_mean_of_dataloader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "File \u001b[1;32md:\\QubotGit\\QubotGitFile\\Qubot_Elastica\\Modeling eMNS\\Training_loop.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearly_stopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, EarlyDecay\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_discrete_curl, denorm, max_min_norm\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjust_learning_rate_sch\u001b[39m(optimizer, lrd, epoch, schedule):\n",
      "File \u001b[1;32md:\\QubotGit\\QubotGitFile\\Qubot_Elastica\\Modeling eMNS\\utils.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "from Neural_network import Generative_net, ResidualEMNSBlock_3d, BigBlock, weight_init, eMNS_Dataset,Generative_net_test\n",
    "from Training_loop import train_part_GM,get_mean_of_dataloader\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 8\n",
    "# construct dataset\n",
    "dataset = eMNS_Dataset(\n",
    "    train_x=current_norm,\n",
    "    train_y=Bfield_norm\n",
    ")\n",
    "###############################################\n",
    "# Config the neural network\n",
    "###############################################\n",
    "num_input = 12\n",
    "output_shape = (3,16,16,16)\n",
    "SB_args = (64,64,1,4) # (Cin, Cout, num_repeat, num_block)\n",
    "BB_args = (2,2) # (scale_factor, num_block)\n",
    "SB_block = ResidualEMNSBlock_3d \n",
    "BB_block = BigBlock\n",
    "DF = False # whether using divergence free model\n",
    "\n",
    "Generative_network = Generative_net(SB_args, BB_args, SB_block, BB_block, num_input=num_input, output_shape= output_shape)\n",
    "epochs = 1\n",
    "learning_rate_decay = .5\n",
    "learning_rates = [1.0e-4]\n",
    "RMSE_lr = []\n",
    "schedule = []\n",
    "linear_lr = False\n",
    "weight_decays = [0]\n",
    "\n",
    "train_percents = np.arange(1.0,1.01,0.1)\n",
    "RMSE_history_end = np.zeros(len(train_percents))\n",
    "RMSE_val_history_end = np.zeros(len(train_percents))\n",
    "loss_history_end = np.zeros(len(train_percents))\n",
    "iter_history_end = np.zeros(len(train_percents))\n",
    "mse_history_end = np.zeros(len(train_percents))\n",
    "mse_val_history_end = np.zeros(len(train_percents))\n",
    "train_stop_epoch = np.zeros(len(train_percents))\n",
    "\n",
    "\n",
    "################################################\n",
    "# Train the neural network\n",
    "################################################\n",
    "index=0\n",
    "for train_percent in train_percents:\n",
    "    epoch_stop = 0\n",
    "    print('train_percent',train_percent)\n",
    "    for learning_rate in tqdm(learning_rates):\n",
    "        for weight_decay in weight_decays:\n",
    "\n",
    "            # split the dataset to train, validation, test\n",
    "            train_set, valid_set = torch.utils.data.random_split(dataset, [0.9,0.1])\n",
    "            print(train_set.shape)\n",
    "            #Using Dataloader for batch train\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)\n",
    "            valid_loader = torch.utils.data.DataLoader(dataset=valid_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "            get_mean_of_dataloader(valid_loader,model=Generative_network,device=device)\n",
    "            print(\"----------------------------\")\n",
    "            \n",
    "            print(\"----------------------------\")\n",
    "            # test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "            Generative_network.apply(weight_init)\n",
    "            optimizer = torch.optim.Adam([{'params':Generative_network.parameters()}], lr=learning_rate, weight_decay= weight_decay, betas=(0.5,0.99))\n",
    "            RMSE_history, RMSE_val_history, loss_history, iter_history, mse_history, mse_val_history,epoch_stop,Rsquare,loss_train,loss_val= train_part_GM(\n",
    "                model=Generative_network, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, epochs=epochs, \n",
    "                learning_rate_decay=learning_rate_decay, weight_decay=weight_decay, schedule=schedule, grid_space= dimB[2]*dimB[3]*dimB[4], DF=DF,verbose=False, device=device, maxB=MaxB[0,:], minB=MinB[0,:],\n",
    "                lr_max=learning_rate, lr_min=2.5e-6,max_epoch=epochs, linear_lr=linear_lr)\n",
    "        \n",
    "        \n",
    "        RMSE_lr.append(RMSE_val_history[epoch_stop].item())\n",
    "    \n",
    "    #save RMSE and loss after early stopping\n",
    "    RMSE_history_end[index] = RMSE_history[epoch_stop]\n",
    "    RMSE_val_history_end[index]= RMSE_val_history[epoch_stop]\n",
    "    loss_history_end[index] = loss_history[epoch_stop]\n",
    "    iter_history_end[index] = iter_history[epoch_stop]\n",
    "    mse_history_end[index] = mse_history[epoch_stop]\n",
    "    mse_val_history_end[index] = mse_val_history[epoch_stop]\n",
    "    index=index+1\n",
    "    print('training stop at epoch:',epoch_stop)\n",
    "    print('training stop at epoch:',Rsquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Generative_network, 'EMS_CNN.pt')\t# 这里会存储迄今最优模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_val.shape)\n",
    "print(loss_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RMSE_lr)\n",
    "print(learning_rates)\n",
    "print(RMSE_lr[0],learning_rates[0])\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(learning_rates,RMSE_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ave_site = 5\n",
    "ave_kernel = 1/ave_site*np.ones(ave_site)\n",
    "loss_history_conv = np.convolve(loss_history.numpy(),ave_kernel,'same')\n",
    "\n",
    "\n",
    "plt.title('loss')\n",
    "plt.plot(iter_history,loss_history,'-o')\n",
    "plt.plot(iter_history,loss_history_conv,'-*')\n",
    "plt.legend(['loss','loss_conv'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title('loss train and val')\n",
    "plt.plot(iter_history[0:epoch_stop],loss_train[0:epoch_stop],'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],loss_val[0:epoch_stop],'-*')\n",
    "plt.legend(['loss_train','loss_val'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('Train and Val RMSE(sample_num=1000)')\n",
    "plt.plot(iter_history[0:epoch_stop],RMSE_history[0:epoch_stop],'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],RMSE_val_history[0:epoch_stop],'-*')\n",
    "# plt.plot(2e-5*np.arange(epoch_stop),RMSE_history[0:epoch_stop]*1000,'-o')\n",
    "# plt.plot(2e-5*np.arange(epoch_stop),RMSE_val_history[0:epoch_stop]*1000,'-*')\n",
    "# plt.ylim([15,20])\n",
    "plt.legend(['train CNN','val CNN'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('RMSE(mT)')\n",
    "# plt.ylim([0,100])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Train and Val loss(sample_num=1000)')\n",
    "plt.plot(iter_history[0:epoch_stop],mse_history[0:epoch_stop],'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],mse_val_history[0:epoch_stop],'-*')\n",
    "plt.legend(['train CNN','val CNN'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('mse(mT^2)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(position[0:1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "# a = torch.range(1,48).reshape(3,4,4)\n",
    "a = torch.randn(3,4,4)\n",
    "b = a+1\n",
    "grad_a = torch.gradient(a)\n",
    "grad_a_x = torch.gradient(a[0])\n",
    "grad_a_y = torch.gradient(a[1])\n",
    "grad_a_z = torch.gradient(a[2])\n",
    "print(len(a))\n",
    "print(grad_a[2])\n",
    "print(grad_a_z)\n",
    "error = torch.sum(grad_a[1] + grad_a[2]) - torch.sum(sum(grad_a_x)+sum(grad_a_y) +sum(grad_a_z))\n",
    "print(error)\n",
    "print(a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Generative_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "from Training_loop import grad_loss\n",
    "x = torch.randn(2,12)\n",
    "y = Bfield[0:2]\n",
    "preds = Generative_network(x)\n",
    "print(preds.shape)\n",
    "loss =   grad_loss(preds,y)\n",
    "        # optimizer.zero_grad() #zero out all of gradient\n",
    "loss.backward()\n",
    "\n",
    "make_dot(loss, params=dict(Generative_network.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
