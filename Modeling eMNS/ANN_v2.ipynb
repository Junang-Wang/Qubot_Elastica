{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook employs a fully connective neural network(FC) or its alias artificial neural network (ANN) to learn the mapping between input current configuration between output magnetic field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from early_stopping import EarlyStopping\n",
    "\n",
    "if torch.cuda.device_count():\n",
    "    device = 'cuda'\n",
    "    print('Good to go')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReadData import ReadCurrentAndField \n",
    "import glob\n",
    "import os \n",
    "\n",
    "# print(os.getcwd())\n",
    "foldername=\"./Data/\"\n",
    "filepattern = \"MagneticField[0-9]*.txt\"\n",
    "#data = ReadFolder(foldername,filepattern)\n",
    "train_file_num = 1000\n",
    "data = ReadCurrentAndField (foldername,filepattern,train_file_num)\n",
    "\n",
    "# fileList = glob.glob(foldername+filepattern)\n",
    "data=data.reshape(train_file_num,21,21,21,18)\n",
    "position = data[:,0:20:2,0:20:2,0:20:2,:15].reshape(-1,15)\n",
    "Bfield = data[:,0:20:2,0:20:2,0:20:2,15:].reshape(-1,3)\n",
    "\n",
    "print(data.shape)\n",
    "print('position shape', position.shape)\n",
    "print('Bfield shape', Bfield.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find min and max value of input position and Bfield\n",
    "max_position, max_position_index = torch.max(position, dim=0, keepdim=True)\n",
    "print(max_position)\n",
    "min_position, min_position_index = torch.min(position, dim=0, keepdim=True)\n",
    "print(min_position)\n",
    "\n",
    "max_Bfield, max_Bfield_index = torch.max(Bfield, dim=0, keepdim=True)\n",
    "print(max_Bfield)\n",
    "min_Bfield, min_Bfield_index = torch.min(Bfield, dim=0, keepdim=True)\n",
    "print(min_Bfield)\n",
    "\n",
    "position_norm = (position-min_position.expand(position.shape[0],position.shape[1]))/(max_position.expand(position.shape[0],position.shape[1])-min_position.expand(position.shape[0],position.shape[1]))\n",
    "Bfield_norm = (Bfield-min_Bfield.expand(Bfield.shape[0],Bfield.shape[1]))/(max_Bfield.expand(Bfield.shape[0],Bfield.shape[1])-min_Bfield.expand(Bfield.shape[0],Bfield.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_network import NN_net, Plain_fc_block, weight_init, eMNS_Dataset\n",
    "from Training_loop import train_part_v1\n",
    "batch_size = 128\n",
    "# construct dataset\n",
    "dataset = eMNS_Dataset(\n",
    "    train_x=position_norm,\n",
    "    train_y=Bfield_norm\n",
    ")\n",
    "###############################################\n",
    "# Config the neural network\n",
    "###############################################\n",
    "num_input = 15\n",
    "num_output = 3\n",
    "fc_stages = [(num_input,100,1),(100,50,1),(50,25,1)]\n",
    "fc_network = NN_net(None,fc_stages,None,Plain_fc_block, num_output=num_output)\n",
    "epochs = 50\n",
    "learning_rate_decay = .1\n",
    "learning_rates = [1e-3]\n",
    "schedule = []\n",
    "weight_decays = [0]\n",
    "\n",
    "train_percents = np.arange(0.9,0.95,0.1)\n",
    "RMSE_history_end = np.zeros(len(train_percents))\n",
    "RMSE_val_history_end = np.zeros(len(train_percents))\n",
    "loss_history_end = np.zeros(len(train_percents))\n",
    "iter_history_end = np.zeros(len(train_percents))\n",
    "loss_val_history_end = np.zeros(len(train_percents))\n",
    "train_stop_epoch = np.zeros(len(train_percents))\n",
    "\n",
    "################################################\n",
    "# Train the neural network\n",
    "################################################\n",
    "index=0\n",
    "for train_percent in train_percents:\n",
    "    epoch_stop = 0\n",
    "    print('train_percent',train_percent)\n",
    "    for learning_rate in learning_rates:\n",
    "        for weight_decay in weight_decays:\n",
    "\n",
    "            # split the dataset to train, validation, test\n",
    "            train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [train_percent*0.9,train_percent*0.1,1.0-train_percent])\n",
    "\n",
    "            #Using Dataloader for batch train\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)\n",
    "            valid_loader = torch.utils.data.DataLoader(dataset=valid_set,batch_size=batch_size,shuffle=True)\n",
    "            test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "            fc_network.apply(weight_init)\n",
    "            optimizer = torch.optim.Adam([{'params':fc_network.parameters()}], lr=learning_rate, weight_decay= weight_decay)\n",
    "            RMSE_history, RMSE_val_history, loss_history, iter_history, loss_val_history,epoch_stop = train_part_v1(model=fc_network, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, epochs=epochs, learning_rate_decay=learning_rate_decay, schedule=schedule, weight_decay=weight_decay, verbose=False, device=device)\n",
    "    \n",
    "    #save RMSE and loss after early stopping\n",
    "    RMSE_history_end[index] = RMSE_history[epoch_stop]\n",
    "    RMSE_val_history_end[index]= RMSE_val_history[epoch_stop]\n",
    "    loss_history_end[index] = loss_history[epoch_stop]\n",
    "    iter_history_end[index] = iter_history[epoch_stop]\n",
    "    loss_val_history_end[index] = loss_val_history[epoch_stop]\n",
    "    index=index+1\n",
    "    print('training stop at epoch:',epoch_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fc_network, 'EMS_ANN.pt')\t# 这里会存储迄今最优模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ave_site = 5\n",
    "ave_kernel = 1/ave_site*np.ones(ave_site)\n",
    "loss_history_conv = np.convolve(loss_history.numpy(),ave_kernel,'same')\n",
    "plt.plot(iter_history[0:epoch_stop],RMSE_history[0:epoch_stop],'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],RMSE_val_history[0:epoch_stop],'-o')\n",
    "plt.legend(['train ANN','val ANN'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iter_history[0:epoch_stop],loss_history[0:epoch_stop],'-o')\n",
    "plt.plot(iter_history[0:epoch_stop],loss_val_history[0:epoch_stop],'-*')\n",
    "plt.legend(['train ANN','val ANN'])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_percents,RMSE_val_history_end,'-o')\n",
    "plt.xlabel('train_percents')\n",
    "plt.ylabel('RMSE(mT)')\n",
    "# plt.ylim([0,25])\n",
    "plt.grid()\n",
    "plt.legend(['ANN'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_percents,loss_history_end,'-o')\n",
    "plt.xlabel('train_percents')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['ANN'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
