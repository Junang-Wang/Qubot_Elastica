{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook employs a fully connective neural network(FC) or its alias artificial neural network (ANN) to learn the mapping between input current configuration between output magnetic field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"ray[data,train,tune,serve]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from early_stopping import EarlyStopping\n",
    "\n",
    "if torch.cuda.device_count():\n",
    "    device = 'cuda'\n",
    "    use_gpu = True\n",
    "    print('Good to go')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    use_gpu = False\n",
    "    print('Using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReadData import ReadCurrentAndField \n",
    "import glob\n",
    "import os \n",
    "\n",
    "# print(os.getcwd())\n",
    "foldername=\"./Data/\"\n",
    "filepattern = \"MagneticField[0-9]*.txt\"\n",
    "#data = ReadFolder(foldername,filepattern)\n",
    "load_file_num = 1460\n",
    "train_file_num = 1000\n",
    "grid_size = 21\n",
    "data = ReadCurrentAndField (foldername,filepattern, load_file_num)\n",
    "\n",
    "\n",
    "data=data.reshape(load_file_num,grid_size,grid_size,grid_size,18)\n",
    "mask = torch.cat((torch.ones(1,1,1,1,12),1e3*torch.ones(1,1,1,1,6)), dim=4)\n",
    "# position unit mm, B field unit mT, Current unit Ampere\n",
    "data = mask*data\n",
    "\n",
    "sparsity = 4\n",
    "\n",
    "Current_position =data[:train_file_num,0::sparsity,0::sparsity,0::sparsity,:15].reshape(-1,15) # position unit mm\n",
    "Bfield = data[:train_file_num,0::sparsity,0::sparsity,0::sparsity,15:].reshape(-1,3) # B field unit mT\n",
    "\n",
    "print(data.shape)\n",
    "print(data[:train_file_num,0::sparsity,0::sparsity,0::sparsity,:15].shape)\n",
    "print('position shape', Current_position.shape)\n",
    "print('Bfield shape', Bfield.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_network import NN_net, Plain_fc_block, weight_init, eMNS_Dataset\n",
    "from Training_loop_v2 import train_ANN\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.tune.tuner import Tuner\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray, os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# construct dataset\n",
    "\n",
    "Current_position =data[:train_file_num,0::sparsity,0::sparsity,0::sparsity,:15].reshape(-1,15) # position unit mm\n",
    "\n",
    "Bfield = data[:train_file_num,0::sparsity,0::sparsity,0::sparsity,15:].reshape(-1,3) # B field unit mT\n",
    "\n",
    "dataset = eMNS_Dataset(\n",
    "    x=Current_position,\n",
    "    y=Bfield\n",
    ")\n",
    "\n",
    "# split the dataset to train, validation, test\n",
    "train_set, valid_set = torch.utils.data.random_split(dataset, [0.9,0.1])\n",
    "\n",
    "# normailzation\n",
    "extremes = dataset.train_norm_ANN(train_indices = train_set.indices, boundary_index=12)\n",
    "\n",
    "###############################################\n",
    "# Config the neural network\n",
    "###############################################\n",
    "num_input = 15\n",
    "num_output = 3\n",
    "fc_stages = [(num_input,128,1),(128,64,1),(64,32,1)]\n",
    "fc_network = NN_net(None,fc_stages,None,Plain_fc_block, num_output=num_output)\n",
    "\n",
    "loss_func = lambda preds, y: F.l1_loss(preds, y)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Train the neural network\n",
    "################################################\n",
    "\n",
    "train_loop_config = {\n",
    "                'epochs': 50,\n",
    "                'lr_max': 1e-3,\n",
    "                'lr_min': 2.5e-6,\n",
    "                'batch_size': 128,\n",
    "                'L2_norm'   : 0,\n",
    "                'verbose': False,\n",
    "                'schedule': [],\n",
    "                'learning_rate_decay': 0.5,\n",
    "                'num_input'   : num_input,\n",
    "                'num_output'  : num_output,\n",
    "                'fc_stages'   : fc_stages,\n",
    "                'backward'    : False,\n",
    "                'maxB'        : extremes[4],\n",
    "                'minB'        : extremes[5],\n",
    "                'device'      : device,\n",
    "                'loss_func'   : loss_func,\n",
    "                'forward_model_path' : None\n",
    "                # You can even grid search various datasets in Tune.\n",
    "                # \"datasets\": tune.grid_search(\n",
    "                #         [ds1, ds2]\n",
    "                #     ),\n",
    "}\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers = 1,\n",
    "    use_gpu = use_gpu,\n",
    "    resources_per_worker = {\"CPU\":7, \"GPU\":1}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(name=\"EMS_ANN_v2\", storage_path= \"~/ray_results\",checkpoint_config=CheckpointConfig(num_to_keep=1))\n",
    "\n",
    "def train_loop_per_worker(params):\n",
    "    train_ANN(train_set=train_set, valid_set=valid_set, config=params)\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker = train_loop_per_worker,\n",
    "    train_loop_config = train_loop_config,\n",
    "    scaling_config = scaling_config,\n",
    "    run_config = run_config,\n",
    "\n",
    ")\n",
    "result = trainer.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(fc_network, (1,15))\n",
    "for param_tensor in fc_network.state_dict():\n",
    "    print(param_tensor, '\\t', fc_network.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_ray_results\n",
    "plot_ray_results(results=result, metrics_names = ['rmse_val','rmse_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_data = torch.load(os.path.join(result.checkpoint.path,\"model.pt\"))\n",
    "\n",
    "model_path = r\"./Trained_model/EMS_ANN_v2.pt\"\n",
    "torch.save(checkpoint_data, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position unit mm, current unit Ampere\n",
    "sparsity = 1\n",
    "Current_position_test =data[train_file_num:, ::sparsity, ::sparsity, ::sparsity, :15].reshape(-1,15) \n",
    "# B field unit mT\n",
    "Bfield_test = data[train_file_num:, ::sparsity, ::sparsity, ::sparsity,15:].reshape(-1,3)\n",
    "\n",
    "num_sample = Current_position_test.shape[0]\n",
    "print('position shape', Current_position_test.shape)\n",
    "print('Bfield shape', Bfield_test.shape)\n",
    "\n",
    "# construct dataset\n",
    "test_set = eMNS_Dataset(\n",
    "    x=Current_position_test,\n",
    "    y=Bfield_test\n",
    ")\n",
    "test_set.test_norm_ANN(extremes=extremes, boundary_index=12)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=train_loop_config['batch_size'],\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict_check_rmse_ANN, check_rmse_ANN\n",
    "from Training_loop_v2 import construct_model_ANN \n",
    "\n",
    "model_path = r\"./Trained_model/EMS_ANN_v2.pt\"\n",
    "model = torch.load(model_path)['model']\n",
    "\n",
    "prediction, rmse, mse, Rsquare = predict_check_rmse_ANN(test_loader, model,config=train_loop_config)\n",
    "# check_rmse_ANN(test_loader, model, device, extremes[4], extremes[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "B_est = prediction.reshape(-1, grid_size, grid_size, grid_size, 3)\n",
    "Bfield_test = Bfield_test.reshape(-1, grid_size, grid_size, grid_size, 3)\n",
    "\n",
    "# B_est = prediction.reshape(-1, 6, 6, 6, 3)\n",
    "# Bfield_test = Bfield_test.reshape(-1, 6, 6, 6, 3)\n",
    "\n",
    "current_index=3\n",
    "z_plane_index= 5\n",
    "# fig, ax = plt.subplots(3, 2)\n",
    "# fig.tight_layout(h_pad=2)\n",
    "fig = plt.figure()\n",
    "ylables=['Bx\\mT','By\\mT','Bz\\mT']\n",
    "# fig.tight_layout(pad=0.4, w_pad=0, h_pad=0)\n",
    "for i in range(1,4):\n",
    "    plt.subplot(3,2,2*i-1)\n",
    "    plt.imshow(B_est[current_index,:,:,z_plane_index,i-1])    \n",
    "    plt.colorbar()\n",
    "    plt.ylabel(ylables[i-1])\n",
    "    plt.subplot(3,2,2*i)\n",
    "    plt.imshow(Bfield_test[current_index,:,:,z_plane_index,i-1])\n",
    "    plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
